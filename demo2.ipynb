{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a65b0696",
   "metadata": {},
   "source": [
    "# Student Performance\n",
    "\n",
    "![The Village School by Albert Anker, 1848](imgs/Students_Cover.png)\n",
    "\n",
    "The first dataset is on math grades, the second dataset is on Portugese language grades\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "12a2cf13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What's good what's good what's good\n",
      "Now we're going to be predicting student grades based on various factors like study time, family size, and the like.\n",
      "Notice that, unlike the image classification task, this database is made up of un-structured data (i.e. one dimension of the input directly cause the other), and we don't need to flatten the data or anything like that.\n",
      "Note that the scale is pretty strange, the students seem to be marked out of 20. Columns G1, G2, and G3 represent the first, second, and third grades respectively\n"
     ]
    }
   ],
   "source": [
    "print(\"What's good what's good what's good\")\n",
    "\n",
    "print(\"Now we're going to be predicting student grades based on various factors like study time, family size, and the like.\")\n",
    "\n",
    "print(\"Notice that, unlike the image classification task, this database is made up of un-structured data (i.e. one dimension of the input directly cause the other), and we don't need to flatten the data or anything like that.\")\n",
    "\n",
    "print(\"Note that the scale is pretty strange, the students seem to be marked out of 20. Columns G1, G2, and G3 represent the first, second, and third grades respectively\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d2887aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lets work on forming the neural network.\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary libraries\n",
    "\n",
    "from nn.network import NeuralNetwork\n",
    "from nn.layer import Layer\n",
    "from nn.loss import MSE, MSE_derivative\n",
    "from nn.activations import relu, relu_derivative, tanh, tanh_derivative\n",
    "from nn.gd import fit\n",
    "from utils.loader import load_student_dataset\n",
    "from utils.splitter import data_split\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(8)\n",
    "\n",
    "def identity(x):\n",
    "    return x\n",
    "\n",
    "def identity_derivative(x):\n",
    "    return np.ones_like(x)\n",
    "\n",
    "print(\"Lets work on forming the neural network.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e7752a",
   "metadata": {},
   "source": [
    "![Math image from Veusz](imgs/mat.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2190371d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Math first\n",
      "Data loaded with 56 features\n"
     ]
    }
   ],
   "source": [
    "print(\"Math first\")\n",
    "\n",
    "X, Y = load_student_dataset('data/student_grades/student-mat.csv')\n",
    "\n",
    "X_train, Y_train, X_val, Y_val, X_test, Y_test = data_split(X, Y, train_ratio=0.7, val_ratio=0.1, seed=42)\n",
    "\n",
    "input_size = X_train.shape[1]\n",
    "l2 = 0.01\n",
    "\n",
    "print(f\"Data loaded with {input_size} features\")\n",
    "# Note that Grades 1 and 2 are excluded from the input and output features so as to make the neural network's job harder\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "094bbc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = NeuralNetwork(loss=MSE, loss_derivative=MSE_derivative)\n",
    "\n",
    "layer1 = Layer(input_size=input_size, output_size=64, activation=tanh, d_activation=tanh_derivative, mask=None, l2_lambda=l2)\n",
    "layer2 = Layer(input_size=64, output_size=32, activation=relu, d_activation=relu_derivative, mask=None, l2_lambda=l2)\n",
    "layer3 = Layer(input_size=32, output_size=1, activation=identity, d_activation=identity_derivative, mask=None)\n",
    "\n",
    "nn.add_layers([layer1, layer2, layer3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e4edf418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Training complete.\n",
      "Final Test MSE (scaled): 0.0283\n",
      "Final grade error: 3.3652253525062754\n"
     ]
    }
   ],
   "source": [
    "print(\"Training...\")\n",
    "\n",
    "test_error = fit(nn, X_train, Y_train, X_val, Y_val, X_test, Y_test, max_epochs=1000, learning_rate=0.001)\n",
    "\n",
    "print(\"Training complete.\")\n",
    "\n",
    "print(f\"Final Test MSE (scaled): {test_error:.4f}\")\n",
    "print(\"Final grade error:\", np.sqrt(test_error) * 20.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5e3ff489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the model...\n"
     ]
    }
   ],
   "source": [
    "print(\"Saving the model...\")\n",
    "\n",
    "nn.save_model('mat_grade_predictor')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed88ffda",
   "metadata": {},
   "source": [
    "![Portugal Flag](imgs/por.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f50f6253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Portuguese marks next\n",
      "Data loaded with 56 features\n"
     ]
    }
   ],
   "source": [
    "print(\"Portuguese marks next\")\n",
    "\n",
    "X, Y = load_student_dataset('data/student_grades/student-por.csv')\n",
    "\n",
    "X_train, Y_train, X_val, Y_val, X_test, Y_test = data_split(X, Y, train_ratio=0.7, val_ratio=0.1, seed=42)\n",
    "\n",
    "input_size = X_train.shape[1]\n",
    "l2 = 0.01\n",
    "\n",
    "print(f\"Data loaded with {input_size} features\")\n",
    "# Note that Grades 1 and 2 are excluded from the input and output features so as to make the neural network's job harder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e8afd75a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making Neural Network.........\n"
     ]
    }
   ],
   "source": [
    "print(\"Making Neural Network.........\")\n",
    "nn = NeuralNetwork(loss=MSE, loss_derivative=MSE_derivative)\n",
    "\n",
    "layer1 = Layer(input_size=input_size, output_size=64, activation=tanh, d_activation=tanh_derivative, mask=None, l2_lambda=l2)\n",
    "layer2 = Layer(input_size=64, output_size=32, activation=relu, d_activation=relu_derivative, mask=None, l2_lambda=l2)\n",
    "layer3 = Layer(input_size=32, output_size=1, activation=identity, d_activation=identity_derivative, mask=None)\n",
    "\n",
    "nn.add_layers([layer1, layer2, layer3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "460d4c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Training complete.\n",
      "Final Test MSE (scaled): 0.0158\n",
      "Final grade error: 2.5122025334652704\n"
     ]
    }
   ],
   "source": [
    "print(\"Training...\")\n",
    "\n",
    "test_error = fit(nn, X_train, Y_train, X_val, Y_val, X_test, Y_test, max_epochs=1000, learning_rate=0.001)\n",
    "\n",
    "print(\"Training complete.\")\n",
    "\n",
    "print(f\"Final Test MSE (scaled): {test_error:.4f}\")\n",
    "print(\"Final grade error:\", np.sqrt(test_error) * 20.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64af6f0f",
   "metadata": {},
   "source": [
    "---\n",
    "Here, we observe something interesting.\n",
    "\n",
    "Notice how, with almost twice as many rows, the accuracy improves significantly.\n",
    "\n",
    "However, it's not as much as you would expect. This indicates something about the data: it's not very \"predictive\". The correlation between the input features and the output grades is not very strong.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "380e7f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now save the model and ta-da we're done\n"
     ]
    }
   ],
   "source": [
    "print(\"Now save the model and ta-da we're done\")\n",
    "\n",
    "nn.save_model('por_grade_predictor')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
